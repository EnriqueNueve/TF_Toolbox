{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NICE with tf==2.4.1 & tfp==0.12.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper: https://arxiv.org/pdf/1410.8516.pdf\n",
    "### Implementation inspiration: https://github.com/DakshIdnani/pytorch-nice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"mnist_784.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    X, y = data.iloc[:,:-1].values/255, data.iloc[:,-1].values/255\n",
    "    X, y = X+np.random.uniform(0,1/256,(X.shape[0],X.shape[1])), y+np.random.uniform(0,1/256,y.shape)\n",
    "else:\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "    X, y = X/255, y.astype(np.float)/255\n",
    "    X, y = X+np.random.uniform(0,1/256,(X.shape[0],X.shape[1])), y+np.random.uniform(0,1/256,y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0,:].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Layer that performs scaling.\"\"\"\n",
    "    def __init__(self,dim):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "        w_init = tf.ones_initializer()\n",
    "        self.S = tf.Variable(\n",
    "            initial_value=w_init(shape=(dim), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, h,log_det_jacob=0, inverse=False):\n",
    "        if inverse == True:\n",
    "            y = tf.multiply(tf.math.exp(-self.S),h)\n",
    "            return y\n",
    "        h = tf.multiply(tf.math.exp(self.S),h)\n",
    "        log_det_jacob = tf.math.reduce_sum(self.S)\n",
    "        return h, log_det_jacob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(keras.layers.Layer):\n",
    "    \"\"\"y = w.x + b\"\"\"\n",
    "    def __init__(self,name,units=32, input_dim=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.w = self.add_weight(name + \"_weight\",\n",
    "                               shape=[input_dim, units],\n",
    "                               regularizer=tf.keras.regularizers.l1_l2(.0001))\n",
    "        self.b = self.add_weight(name + \"_bias\",\n",
    "                               shape=[units],\n",
    "                               regularizer=tf.keras.regularizers.l1_l2(.0001))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveCouple(tf.keras.layers.Layer):\n",
    "    def __init__(self,name, dim, mask,couple_dim):\n",
    "        super(AdditiveCouple, self).__init__()\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.couple_dim = couple_dim\n",
    "        self.mask = mask\n",
    "        \n",
    "        # Declare layers of NeuralNet~m\n",
    "        self.l1 = Linear(name+'1',self.couple_dim,self.dim)\n",
    "        self.l2 = Linear(name+'2',self.couple_dim,self.couple_dim)\n",
    "        self.l3 = Linear(name+'3',self.couple_dim,self.couple_dim)\n",
    "        self.l4 = Linear(name+'4',self.couple_dim,self.couple_dim)\n",
    "        self.l5 = Linear(name+'5',self.dim,self.couple_dim)\n",
    "\n",
    "    def m(self,x):\n",
    "        x = self.l1(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.l3(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        x = self.l4(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        return self.l5(x)\n",
    "\n",
    "    def call(self, x, inverse=False):\n",
    "        if inverse == True:\n",
    "            y1, y2 = self.mask*x, (1-self.mask)*x \n",
    "            x1, x2 = y1, y2-(self.m(y1)*(1-self.mask))\n",
    "            return x1+x2\n",
    "        else:\n",
    "            x1, x2 = self.mask*x, (1-self.mask)*x\n",
    "            y1, y2 = x1, x2+(self.m(x1)*(1-self.mask))\n",
    "            return y1+y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NICE(keras.Model):\n",
    "    def __init__(self,input_dim,n_couple, couple_dim,**kwargs):\n",
    "        super(NICE, self).__init__(**kwargs)\n",
    "\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.prior = tfp.distributions.Logistic(0,1)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.n_couple = n_couple\n",
    "        self.couple_dim = couple_dim\n",
    "\n",
    "        masks = [self._get_mask(self.input_dim, orientation=(i % 2 == 0)) for i in range(self.n_couple)]\n",
    "        \n",
    "        # Declare coupling layers\n",
    "        self.coupling_layers = []\n",
    "        for i in range(self.n_couple-1):\n",
    "            add_couple = AdditiveCouple(str(i) ,self.input_dim,masks[i],self.couple_dim)\n",
    "            self.coupling_layers.append(add_couple)\n",
    "        \n",
    "        # Declare Scaling layer\n",
    "        self.S = ScaleLayer(dim=input_dim)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"List of the model's metrics.\n",
    "        We make sure the loss tracker is listed as part of `model.metrics`\n",
    "        so that `fit()` and `evaluate()` are able to `reset()` the loss tracker\n",
    "        at the start of each epoch and at the start of an `evaluate()` call.\n",
    "        \"\"\"\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    def _get_mask(self, dim, orientation=True):\n",
    "        mask = np.zeros(dim)\n",
    "        mask[::2] = 1.\n",
    "        if orientation:\n",
    "            mask = 1. - mask  # flip mask orientation\n",
    "        return mask\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        X, y = data[0], data[1]\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Feed input through model \n",
    "            h, s_vals = self(X)\n",
    "            \n",
    "            # Caculate loss, prior is standard logistic\n",
    "            loss = s_vals + tf.math.reduce_sum(self.prior.log_prob(h),axis=1)\n",
    "            loss = -tf.math.reduce_mean(loss)\n",
    "            \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        #grads = [tf.clip_by_norm(g, 1)for g in grads]\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\n",
    "            \"log_likelihood\": self.loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        X, y = data[0], data[1]\n",
    "        h, s_vals = self(X)\n",
    "        loss = s_vals + tf.math.reduce_sum(self.prior.log_prob(h),axis=1)\n",
    "        loss = -tf.math.reduce_mean(loss)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "    \n",
    "    def call(self,x,inverse=False,pass_inv=False):\n",
    "        log_det_jacob = 0\n",
    "        if inverse == True:\n",
    "            if pass_inv == False:\n",
    "                h = np.random.logistic(x,1, self.input_dim)\n",
    "                h = np.reshape(h,(1,self.input_dim))\n",
    "            elif pass_inv == True:\n",
    "                h = x\n",
    "\n",
    "            x = self.S(h,inverse=True)\n",
    "            for layer in reversed(self.coupling_layers):\n",
    "                x = layer(x,inverse=True)\n",
    "            return x\n",
    "        else:\n",
    "            for layer in self.coupling_layers:\n",
    "                x = layer(x)\n",
    "            h, log_det_jacob = self.S(x,log_det_jacob)\n",
    "            return h, log_det_jacob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=3e-4,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model = NICE(input_dim=784,n_couple=4,couple_dim=1000)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 21s 114ms/step - log_likelihood: 348.5646 - val_loss: 288.4555\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 19s 113ms/step - log_likelihood: 276.3573 - val_loss: 245.3453\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 19s 113ms/step - log_likelihood: 233.9475 - val_loss: 204.2001\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: 193.5849 - val_loss: 164.7307\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 18s 108ms/step - log_likelihood: 154.2091 - val_loss: 126.9213\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 18s 107ms/step - log_likelihood: 115.7094 - val_loss: 89.3609\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 18s 107ms/step - log_likelihood: 77.5973 - val_loss: 50.7586\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 18s 108ms/step - log_likelihood: 39.6195 - val_loss: 14.0384\n",
      "Epoch 9/100\n",
      "165/165 [==============================] - 17s 106ms/step - log_likelihood: 2.2288 - val_loss: -21.7761\n",
      "Epoch 10/100\n",
      "165/165 [==============================] - 17s 106ms/step - log_likelihood: -34.9272 - val_loss: -60.3326\n",
      "Epoch 11/100\n",
      "165/165 [==============================] - 19s 114ms/step - log_likelihood: -71.7449 - val_loss: -96.4715\n",
      "Epoch 12/100\n",
      "165/165 [==============================] - 20s 119ms/step - log_likelihood: -108.5325 - val_loss: -131.8102\n",
      "Epoch 13/100\n",
      "165/165 [==============================] - 21s 130ms/step - log_likelihood: -144.9166 - val_loss: -168.5978\n",
      "Epoch 14/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -181.3147 - val_loss: -202.3109\n",
      "Epoch 15/100\n",
      "165/165 [==============================] - 19s 116ms/step - log_likelihood: -216.8583 - val_loss: -238.2890\n",
      "Epoch 16/100\n",
      "165/165 [==============================] - 19s 117ms/step - log_likelihood: -252.4522 - val_loss: -275.3740\n",
      "Epoch 17/100\n",
      "165/165 [==============================] - 18s 109ms/step - log_likelihood: -287.7295 - val_loss: -308.8166\n",
      "Epoch 18/100\n",
      "165/165 [==============================] - 18s 107ms/step - log_likelihood: -322.7908 - val_loss: -343.4009\n",
      "Epoch 19/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -357.3789 - val_loss: -378.2722\n",
      "Epoch 20/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -392.1655 - val_loss: -409.2511\n",
      "Epoch 21/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -425.9120 - val_loss: -442.8587\n",
      "Epoch 22/100\n",
      "165/165 [==============================] - 17s 105ms/step - log_likelihood: -459.4673 - val_loss: -475.6628\n",
      "Epoch 23/100\n",
      "165/165 [==============================] - 17s 106ms/step - log_likelihood: -493.1190 - val_loss: -508.9717\n",
      "Epoch 24/100\n",
      "165/165 [==============================] - 19s 115ms/step - log_likelihood: -526.3876 - val_loss: -540.7330\n",
      "Epoch 25/100\n",
      "165/165 [==============================] - 19s 117ms/step - log_likelihood: -559.1693 - val_loss: -572.4152\n",
      "Epoch 26/100\n",
      "165/165 [==============================] - 19s 113ms/step - log_likelihood: -591.8093 - val_loss: -602.0764\n",
      "Epoch 27/100\n",
      "165/165 [==============================] - 18s 107ms/step - log_likelihood: -623.4984 - val_loss: -634.4042\n",
      "Epoch 28/100\n",
      "165/165 [==============================] - 18s 109ms/step - log_likelihood: -655.9299 - val_loss: -665.4746\n",
      "Epoch 29/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -686.7509 - val_loss: -688.9531\n",
      "Epoch 30/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -717.5381 - val_loss: -716.9341\n",
      "Epoch 31/100\n",
      "165/165 [==============================] - 21s 127ms/step - log_likelihood: -747.8154 - val_loss: -753.1954\n",
      "Epoch 32/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -778.1038 - val_loss: -770.2105\n",
      "Epoch 33/100\n",
      "165/165 [==============================] - 19s 117ms/step - log_likelihood: -805.6904 - val_loss: -804.1744\n",
      "Epoch 34/100\n",
      "165/165 [==============================] - 19s 117ms/step - log_likelihood: -836.3515 - val_loss: -829.6872\n",
      "Epoch 35/100\n",
      "165/165 [==============================] - 19s 114ms/step - log_likelihood: -864.1776 - val_loss: -856.7096\n",
      "Epoch 36/100\n",
      "165/165 [==============================] - 19s 113ms/step - log_likelihood: -893.3129 - val_loss: -884.0015\n",
      "Epoch 37/100\n",
      "165/165 [==============================] - 19s 113ms/step - log_likelihood: -918.6851 - val_loss: -916.8663\n",
      "Epoch 38/100\n",
      "165/165 [==============================] - 18s 108ms/step - log_likelihood: -947.9355 - val_loss: -931.6383\n",
      "Epoch 39/100\n",
      "165/165 [==============================] - 18s 109ms/step - log_likelihood: -972.5196 - val_loss: -939.5765\n",
      "Epoch 40/100\n",
      "165/165 [==============================] - 19s 114ms/step - log_likelihood: -997.1662 - val_loss: -981.4394\n",
      "Epoch 41/100\n",
      "165/165 [==============================] - 19s 113ms/step - log_likelihood: -1023.0775 - val_loss: -1001.6589\n",
      "Epoch 42/100\n",
      "165/165 [==============================] - 19s 117ms/step - log_likelihood: -1049.0677 - val_loss: -1023.1494\n",
      "Epoch 43/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1072.1807 - val_loss: -1037.5912\n",
      "Epoch 44/100\n",
      "165/165 [==============================] - 20s 119ms/step - log_likelihood: -1096.9276 - val_loss: -1076.7781\n",
      "Epoch 45/100\n",
      "165/165 [==============================] - 20s 119ms/step - log_likelihood: -1119.9478 - val_loss: -1077.7700\n",
      "Epoch 46/100\n",
      "165/165 [==============================] - 19s 112ms/step - log_likelihood: -1142.8989 - val_loss: -1114.3468\n",
      "Epoch 47/100\n",
      "165/165 [==============================] - 20s 119ms/step - log_likelihood: -1164.8944 - val_loss: -1129.7837\n",
      "Epoch 48/100\n",
      "165/165 [==============================] - 20s 120ms/step - log_likelihood: -1187.5978 - val_loss: -1131.3108\n",
      "Epoch 49/100\n",
      "165/165 [==============================] - 20s 119ms/step - log_likelihood: -1205.3787 - val_loss: -1164.7892\n",
      "Epoch 50/100\n",
      "165/165 [==============================] - 20s 120ms/step - log_likelihood: -1229.5645 - val_loss: -1160.9744\n",
      "Epoch 51/100\n",
      "165/165 [==============================] - 20s 119ms/step - log_likelihood: -1244.7072 - val_loss: -1194.4882\n",
      "Epoch 52/100\n",
      "165/165 [==============================] - 19s 116ms/step - log_likelihood: -1266.2564 - val_loss: -1201.0234\n",
      "Epoch 53/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1282.9313 - val_loss: -1230.3928\n",
      "Epoch 54/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1305.2444 - val_loss: -1234.7128\n",
      "Epoch 55/100\n",
      "165/165 [==============================] - 18s 112ms/step - log_likelihood: -1319.8928 - val_loss: -1252.5094\n",
      "Epoch 56/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1336.5225 - val_loss: -1271.6791\n",
      "Epoch 57/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1355.5226 - val_loss: -1280.6643\n",
      "Epoch 58/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1372.1137 - val_loss: -1300.3529\n",
      "Epoch 59/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1390.4645 - val_loss: -1308.0947\n",
      "Epoch 60/100\n",
      "165/165 [==============================] - 18s 112ms/step - log_likelihood: -1406.6686 - val_loss: -1321.5323\n",
      "Epoch 61/100\n",
      "165/165 [==============================] - 18s 112ms/step - log_likelihood: -1415.0763 - val_loss: -1335.6278\n",
      "Epoch 62/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1435.0956 - val_loss: -1353.5084\n",
      "Epoch 63/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1444.9450 - val_loss: -1364.5034\n",
      "Epoch 64/100\n",
      "165/165 [==============================] - 21s 125ms/step - log_likelihood: -1461.0056 - val_loss: -1376.9509\n",
      "Epoch 65/100\n",
      "165/165 [==============================] - 19s 112ms/step - log_likelihood: -1477.5895 - val_loss: -1379.5186\n",
      "Epoch 66/100\n",
      "165/165 [==============================] - 18s 112ms/step - log_likelihood: -1489.8370 - val_loss: -1396.4604\n",
      "Epoch 67/100\n",
      "165/165 [==============================] - 18s 112ms/step - log_likelihood: -1503.6740 - val_loss: -1414.4578\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1515.2243 - val_loss: -1412.5121\n",
      "Epoch 69/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1526.8308 - val_loss: -1416.5039\n",
      "Epoch 70/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1538.9439 - val_loss: -1421.8021\n",
      "Epoch 71/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1547.3010 - val_loss: -1436.7897\n",
      "Epoch 72/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1559.1950 - val_loss: -1453.8265\n",
      "Epoch 73/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1574.7733 - val_loss: -1460.1418\n",
      "Epoch 74/100\n",
      "165/165 [==============================] - 18s 112ms/step - log_likelihood: -1582.3375 - val_loss: -1452.4431\n",
      "Epoch 75/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1589.7883 - val_loss: -1487.5355\n",
      "Epoch 76/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1604.0270 - val_loss: -1488.3459\n",
      "Epoch 77/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1614.7571 - val_loss: -1486.2203\n",
      "Epoch 78/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1623.6934 - val_loss: -1503.8451\n",
      "Epoch 79/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1629.9291 - val_loss: -1460.7069\n",
      "Epoch 80/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1639.4479 - val_loss: -1514.1033\n",
      "Epoch 81/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1651.3978 - val_loss: -1521.5104\n",
      "Epoch 82/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1659.3796 - val_loss: -1502.8588\n",
      "Epoch 83/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1663.0211 - val_loss: -1514.5835\n",
      "Epoch 84/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1666.8502 - val_loss: -1542.2528\n",
      "Epoch 85/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1681.9873 - val_loss: -1559.2854\n",
      "Epoch 86/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1694.9466 - val_loss: -1564.4436\n",
      "Epoch 87/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1704.2150 - val_loss: -1560.0432\n",
      "Epoch 88/100\n",
      "165/165 [==============================] - 18s 112ms/step - log_likelihood: -1708.9803 - val_loss: -1555.6643\n",
      "Epoch 89/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1709.3268 - val_loss: -1569.7725\n",
      "Epoch 90/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1719.9439 - val_loss: -1570.6873\n",
      "Epoch 91/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1721.6379 - val_loss: -1578.3300\n",
      "Epoch 92/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1732.2562 - val_loss: -1592.5938\n",
      "Epoch 93/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1735.1524 - val_loss: -1541.6647\n",
      "Epoch 94/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1735.2986 - val_loss: -1590.2595\n",
      "Epoch 95/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1749.2902 - val_loss: -1593.2108\n",
      "Epoch 96/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1757.5825 - val_loss: -1593.4158\n",
      "Epoch 97/100\n",
      "165/165 [==============================] - 18s 110ms/step - log_likelihood: -1763.3828 - val_loss: -1579.8032\n",
      "Epoch 98/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1753.4018 - val_loss: -1622.5248\n",
      "Epoch 99/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1783.2775 - val_loss: -1622.6631\n",
      "Epoch 100/100\n",
      "165/165 [==============================] - 18s 111ms/step - log_likelihood: -1785.5256 - val_loss: -1619.2731\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\\\n",
    "                    epochs=100, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"NICE_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NICE(input_dim=784,n_couple=4,couple_dim=1000)\n",
    "x = np.ones((1,784))\n",
    "x = model(x, inverse=True, pass_inv=True)\n",
    "model.load_weights(\"nice_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.logistic(0,.2, 784)\n",
    "x = np.reshape(x,(1,784))\n",
    "x = model(x, inverse=True, pass_inv=True)\n",
    "x = x.numpy()\n",
    "plt.imshow(x.reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "tfp-env",
   "language": "python",
   "name": "anaconda-tfp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "nteract": {
   "version": "0.27.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
